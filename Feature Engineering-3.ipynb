{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51df29f6-af61-4311-9a8e-eee7e44fe090",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "Ans- Min-Max is a normalization techniques used in data preprocessing to rescale the features of a dataset to a fixed range,typically [0,1] or [-1,1]. The formula for Min-Max scaling is \n",
    "\n",
    "\r\n",
    "$$\r\n",
    "\\[\r\n",
    "X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}$$\r\n",
    "\\]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\\text{Where:}\r\n",
    "\\begin{align*}\r\n",
    "X & \\text{ is the original value} \\\\\r\n",
    "X_{\\text{min}} & \\text{ is the minimum value in the dataset} \\\\\r\n",
    "X_{\\text{max}} & \\text{ is the maximum value in the dataset} \\\\\r\n",
    "X_{\\text{scaled}} & \\text{ is the scaled value}\r\n",
    "\\end{align*}\r\n",
    "\r\n",
    "\r\n",
    "\n",
    "\\end{align*}\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e67126-d4f5-4c77-a223-382d959a017f",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "X original = 10,20,30,40,50\n",
    "\n",
    "by using formula \n",
    "\n",
    "X scaled = 0.0,0.25,0.5,0.75,1.0\n",
    "\n",
    "\n",
    "Application :\n",
    "\n",
    "- Deep Learning : Speeds up training\n",
    "- Distance-Based Models (e.g., KNN) : Ensures fair distance calculation\n",
    "- Visualization : Uniform scaling aids better interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e7134-c5d9-471c-bbd1-94ae690beab7",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "Ans - Unit Vector Scalling , also known as Normalization to Unit Norms  , is a feature scaling techniques that scales each data points to have a unit norm (i.e., the magnitude of each data vector  become 1).\n",
    "\n",
    "Difference from Min-Max Scaling \n",
    "- Min-Max Scalling: Rescales data to a fixed range (e.g., [0,1])\n",
    "- Unit Vector Scalling : Ensures the entire vector has a length of 1 focusing on direction rather than range\n",
    "\n",
    "  Example :\n",
    "\n",
    "Consider two feature for a data points X = [3,4]\n",
    "1. Compute the norm \n",
    "$$\r\n",
    "\\[\r\n",
    "\\|\\mathbf{X}\\| = \\sqrt{3^2 + 4^2} = 5$$\r\n",
    "2. Scale each value\n",
    "   $$X_{\\text{normalized}} = \\left[ \\frac{3}{5}, \\frac{4}{5} \\right] = [0.6, 0.8]$$\r\n",
    "\n",
    "   \\]\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3732f9-0243-41dc-9309-276aab2ecc21",
   "metadata": {},
   "source": [
    "Application \n",
    "- Cosine Similarity : Makes data suitable for angle- based similarity\n",
    "- Clustering : Focuses on Directional relationship rather than magnitude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5363c-ab2f-463e-9e4b-c262dadc859c",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\r\n",
    "example to illustrate its applicatio\n",
    "\n",
    "Ans- PCA is a dimensionality reduction techniques that transform a dataset into a smaller set of variable, called principal component, while retaining as much variance(information) as possible \n",
    "\n",
    "\n",
    "How PCA Works \n",
    "1. Standardize Data : Ensure features have a mean of 0 and unit variance\n",
    "2. Compute Covariance Matrix : Understand features relationships\n",
    "3. Eigen Decompostion: Find eigenvalues and eigenvector of the covariance matrix\n",
    "4. Select Principal Components : Choose components that explain the most variance\n",
    "5. Transform Data : Project the original data onto the selected components\n",
    "\n",
    "WHy USe PCA \n",
    "- Reduces dimensionality to improve computational efficency\n",
    "- Mitigates the \"curse of dimensionality\"\n",
    "- Removes redundant features (correlated data)\n",
    "\n",
    "Example \n",
    "\n",
    "X1 = 2,3,4\n",
    "X2 = 4,6,8\n",
    "\n",
    "steps \n",
    "1. PCA identifies that X2 is a linear combination of X1\n",
    "2. PCA reduces the dataset to a single principal component PC1 repersenting most of the variance\n",
    "\n",
    "OUTPUT \n",
    "PC1 = 1,2,3\n",
    "\n",
    "\n",
    "Application \n",
    "\n",
    "- data visualization :Projects high -dimenesional data to 2d or 3d for plotting\n",
    "- Feature Reduction : Prepares data for machine learning models\n",
    "- Noise Removal: Retains significant pattern while discarding noise \n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92225fa1-01b9-4b3e-822e-f7821eaeb3aa",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\r\n",
    "Extraction? Provide an example to illustrate this concept\n",
    "\n",
    "Ans : PCA is feature extraction technique that creates new feature ,called principal component ,by combining  original features to captures the most variance in the data .Unlike feature selection, PCA generates new,informative features rather than existing ones \n",
    "\n",
    "USING PCA for feature Extraction\n",
    "\n",
    "1. Find Variance : PCA identifies directional (principal components) with the most variance\n",
    "2. Reduce Dimensionality : Select the top k component that explain most variance\n",
    "3. Transform Data : Original features are replaced with the selected principal components\n",
    "\n",
    "Example \n",
    "\n",
    "X1 = 2,3,4\n",
    "X2 = 4,6,8\n",
    "\n",
    "steps \n",
    "1. PCA identifies that X2 is a linear combination of X1\n",
    "2. PCA reduces the dataset to a single principal component PC1 repersenting most of the variance\n",
    "\n",
    "OUTPUT \n",
    "PC1 = 1,2,3\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ffb164-d552-48ec-bb5a-589d74f384c9",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "Ans- \n",
    "Min-Max scaling is useful for preprocessing features like price ,rating , and delivery time they have different units and ranges. By scalling  these features  to a common range (e.g.,[0,1] , their impact on the recommendation model becomes balanced \n",
    "\n",
    "- Equal Influence : Prevent features with larger ranges (e.g., prices) from dominating the model\n",
    "- Model Efiiciency : Helps gradient-based models coverges faster.\n",
    "- Fair Comparisions : Enables effective distance -based calculations for similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5faae-187a-4f0b-84f5-2d3e04badc91",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "Ans - \n",
    "1. Standardize the data : Normalize all features to have a mean of 0 and a standard deviation of 1\n",
    "2. Compute Covariance matrix : Identify correlations between features\n",
    "3. Eigen Decomposition : Extract eigenvectors(principal components)eigenvalues(variance explained)\n",
    "4. Select Principal Component : Retain component that explain 95-99% of the variance using cumalative variance plot\n",
    "5. Transform the data : Project original features onto the selected components to reduce dimensions.\n",
    "6. Model Building : Train the pridiction model on the reduced dataset  for efficency and reduced overfitting\n",
    "\n",
    "Using Pca , you can reduce hundereds of markets trend indicators and financials ratios onto a smaller set of component that capture most of the important patterns, ensures that the prediction model is computationally efficient and less prone to overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8adb55-a4e1-4d17-9e69-0f2a23698f5b",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "\n",
    "Ans - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beb8788f-95ae-4e65-83f0-75797b8f72f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ],\n",
       "       [-0.57894737],\n",
       "       [-0.05263158],\n",
       "       [ 0.47368421],\n",
       "       [ 1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([1,5,10,15,20]).reshape(-1,1)\n",
    "\n",
    "min_max = MinMaxScaler(feature_range= (-1,1))\n",
    "min_max.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f772f8e-ffaf-4c3b-a1f0-cecba7b6c1f0",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "Ans -\n",
    "1. Standardize the data to have mean 0 and 1\n",
    "2. Compute the covariance matrix and perform eigen decomposition\n",
    "3. Select principal components based on explained variance\n",
    "- Retain enough components to explain 95 to 99% of the variance\n",
    "- For example , if the first 3 component explain 86% and 4 component explain 94% , retain 3 or 4 component  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecdc50-398c-4b4d-8d2c-fa15bad1d269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
